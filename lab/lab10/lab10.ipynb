{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1DrI4xJu_LZ9",
      "metadata": {
        "id": "1DrI4xJu_LZ9"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmckim/materials-sp24-colab/blob/main/lab/lab10/lab10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6r8_dQG2_dZt",
      "metadata": {
        "id": "6r8_dQG2_dZt"
      },
      "source": [
        "## Before you start - Save this notebook!\n",
        "\n",
        "When you open a new Colab notebook from the WebCampus (like you hopefully did for this one), you cannot save changes. So it's  best to store the Colab notebook in your personal drive `\"File > Save a copy in drive...\"` **before** you do anything else.\n",
        "\n",
        "The file will open in a new tab in your web browser, and it is automatically named something like: \"**Copy of lab10.ipynb**\". You can rename this to just the title of the assignment \"**lab10.ipynb**\". Make sure you do keep an informative name (like the name of the assignment) so that you know which files to submit back to WebCampus for grading! More instructions on this are at the end of the notebook.\n",
        "\n",
        "\n",
        "**Where does the notebook get saved in Google Drive?**\n",
        "\n",
        "By default, the notebook will be copied to a folder called ‚ÄúColab Notebooks‚Äù at the root (home directory) of your Google Drive. If you use this for other courses or personal code notebooks, I recommend creating a folder for this course and then moving the assignments AFTER you have completed them. <br>\n",
        "\n",
        "I also recommend you give the folder where you save your notebooks^ a different name than the folder we create below that will store the notebook resources you need each time you work through a course notebook. This includes any data files you will need, links to the images that appear in the notebook, and the files associated with the autograder for answer checking.<br>\n",
        "You should select a name other than '**NS499-DataSci-course-materials**'. <br>\n",
        "This folder gets overwritten with each assignment you work on in the course, so you should **NOT** store your notebooks in this folder that we use for course materials! <br><br>For example, you could create a folder called 'NS499-**notebooks**' or something along those lines.\n",
        "\n",
        "__________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PV6CzfogGbEE",
      "metadata": {
        "id": "PV6CzfogGbEE"
      },
      "source": [
        "### Import and Setup Steps\n",
        "If you restart colab, you must rerun all **5** steps in each of these cells!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dhju4HYZGWsP",
      "metadata": {
        "id": "dhju4HYZGWsP"
      },
      "outputs": [],
      "source": [
        "# Step 1\n",
        "# Setup and add files needed to access gdrive\n",
        "from google.colab import drive                                   # these lines mount your gdrive to access the files we import below\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xO_Q1Dr0GX4D",
      "metadata": {
        "id": "xO_Q1Dr0GX4D"
      },
      "outputs": [],
      "source": [
        "# Step 2\n",
        "# Change directory to the correct location in gdrive (modified way to do this from before)\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/NS499-DataSci-course-materials/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1uKV6XI-GY55",
      "metadata": {
        "id": "1uKV6XI-GY55"
      },
      "outputs": [],
      "source": [
        "# Step 3\n",
        "# Remove the files that were previously there- we will replace with all the old + new ones for this assignment\n",
        "!rm -r materials-sp24-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h4s6aRvBGc4Q",
      "metadata": {
        "id": "h4s6aRvBGc4Q"
      },
      "outputs": [],
      "source": [
        "# Step 4\n",
        "# These lines clone (copy) all the files you will need from where I store the code+data for the course (github)\n",
        "# Second part of the code copies the files to this location and folder in your own gdrive\n",
        "!git clone https://github.com/tmckim/materials-sp24-colab '/content/gdrive/My Drive/NS499-DataSci-course-materials/materials-sp24-colab/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CST2q_5bGeRo",
      "metadata": {
        "id": "CST2q_5bGeRo"
      },
      "outputs": [],
      "source": [
        "# Step 5\n",
        "# Change directory into the folder where the resources for this assignment are stored in gdrive (modified way from before)\n",
        "os.chdir('/content/gdrive/MyDrive/NS499-DataSci-course-materials/materials-sp24-colab/lab/lab10/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RavmKgVSFjmo",
      "metadata": {
        "collapsed": true,
        "id": "RavmKgVSFjmo"
      },
      "outputs": [],
      "source": [
        "# Import packages and other things needed\n",
        "# Don't change this cell; Just run this cell\n",
        "# If you restart colab, make sure to run this cell again after the first ones above^\n",
        "\n",
        "import pandas as pd\n",
        "from datascience import *\n",
        "import numpy as np\n",
        "import seaborn as sns                 # this one is new!\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AiZeTvH3Fjmo",
      "metadata": {
        "id": "AiZeTvH3Fjmo"
      },
      "source": [
        "## Conversion Notebook: From `datascience` library to Python's `pandas` library"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yQJI30qlFjmp",
      "metadata": {
        "id": "yQJI30qlFjmp"
      },
      "source": [
        "Throughout this course, we have been working with the `datascience` library, a library created by faculty at UC Berkeley. While this library is not used outside of teaching in these courses, all of the ideas and concepts behind the library and the different functions are definitely used when dealing with data science problems in the real world. <br><br>\n",
        "One of the common libraries used in industry is called `pandas`, and is a way to structure and analyze rectangular/tabular data. Using the `datascience` library in this course is a solid stepping stone to understanding `pandas` better. Throughout this notebook, we will go over certain concepts that we saw in the `datascience` library and showing the equivalent functions that we will use in `pandas`. <br>The syntax and function names may be different but the underlying concepts are still the same!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zaHP1pjWFjmq",
      "metadata": {
        "id": "zaHP1pjWFjmq"
      },
      "source": [
        "Above, we `import pandas as pd`, which means that any function associated with pandas should be called using `pd.function_name()`. This tells Python that we want to use the specific `function_name` from the Pandas library. In theory, we could do `import pandas as pandas` or any other name, but it is known and commonly used to import it as `pd`. We will see some examples of this later in this notebook.\n",
        "\n",
        "For reference:\n",
        "\n",
        "Datascience documentation: http://data8.org/datascience/index.html\n",
        "\n",
        "Python Reference: http://data8.org/python-reference/python-reference.html\n",
        "\n",
        "Pandas documentation: https://pandas.pydata.org/pandas-docs/stable/dsintro.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YIV262_SpqsH",
      "metadata": {
        "id": "YIV262_SpqsH"
      },
      "source": [
        "## **Learning objectives:**\n",
        "\n",
        "\n",
        "*   Work with the package `pandas` üêº\n",
        "*   Compare and contrast similarities and differences between `datascience` and `pandas` ‚úÖ ‚ùå\n",
        "*   Apply skills learned from one package to another üíª\n",
        "*   Find documentation and resources when questions arise ‚ùì\n",
        "*   Practice skills from this course so far with a published neuroscience dataset üß†\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "itM2je14Fjmq",
      "metadata": {
        "id": "itM2je14Fjmq"
      },
      "source": [
        "---\n",
        "\n",
        "### Tables and DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QnewCyukFjmq",
      "metadata": {
        "id": "QnewCyukFjmq"
      },
      "source": [
        "In `datascience`, we have something called a Table, which is a way to organize your data in a tabular format, which makes accessing rows and columns of data easier. <br>\n",
        "In `pandas`, this structure is called a DataFrame. A DataFrame is the primary data structure in `pandas`. <br>Similar to a Table, we can access different rows and columns of a DataFrame. Tables are essentially the same as DataFrames: we can do similar actions and functions with both.\n",
        "\n",
        "In the following lines of code, we create a Table and DataFrame of data by importing and reading an external [csv file](https://en.wikipedia.org/wiki/Comma-separated_values). The Table will be called `cones_table` and the DataFrame will be called `cones_df`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MJOiQZNRw1JV",
      "metadata": {
        "id": "MJOiQZNRw1JV"
      },
      "source": [
        "---\n",
        "### About the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97ENPXSl85Uh",
      "metadata": {
        "id": "97ENPXSl85Uh"
      },
      "source": [
        "We will use a published neuroscience dataset. Citation for the data is: <br>\n",
        "Marcus, D. S., Wang, T. H., Parker, J., Csernansky, J. G., Morris, J. C., & Buckner, R. L. (2007). Open Access Series of Imaging Studies (OASIS): Cross-sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older Adults. Journal of Cognitive Neuroscience, 19(9), 1498‚Äì1507. https://doi.org/10.1162/jocn.2007.19.9.1498 <br>\n",
        "\n",
        "You can also download the paper directly from [here](https://drive.google.com/uc?export=view&id=1AvvCH-CCJFKgntMEj00W2PwpLEIXBxL9) if you'd like to review it (not necessary though)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0hcyIBU-VQq",
      "metadata": {
        "id": "e0hcyIBU-VQq"
      },
      "source": [
        "This dataset consists of a cross-sectional collection of 416 subjects aged 18 to 96. The subjects are all right-handed and include both men and women. 100 of the included subjects over the age of 60 have been clinically diagnosed with very mild to moderate Alzheimer‚Äôs disease (AD). Additionally, a reliability data set is included containing 20 nondemented subjects imaged on a subsequent visit within 90 days of their initial session. The data is also available to download via [Kaggle](https://www.kaggle.com/datasets/jboysen/mri-and-alzheimers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZMwy2TLV-ran",
      "metadata": {
        "id": "ZMwy2TLV-ran"
      },
      "source": [
        "Here is an image from the paper that explains some of the variables in the dataset: <br>\n",
        "\n",
        "![](DataVariableTable.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NzTAp3mIAI6Y",
      "metadata": {
        "id": "NzTAp3mIAI6Y"
      },
      "source": [
        "In addition, there are other variables including: <br>\n",
        "`ID`: individual unique identifier <br>\n",
        "`Hand`: indicates dominant hand. Should all be 'R' for right-handed <br>\n",
        "`Delay`: time between sessions (number of days) for the subset of subjects that returned for a reliabity session"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hACKJAxQBJGO",
      "metadata": {
        "id": "hACKJAxQBJGO"
      },
      "source": [
        "Clinical Dementia Rating (CDR) classification was as follows: <br>\n",
        "\n",
        "\n",
        "*   0 = Normal\n",
        "*   0.5 = Very Mild Dementia\n",
        "*   1 = Mild Dementia\n",
        "*   2 = Moderate Dementia\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gpT8l7T4w2_l",
      "metadata": {
        "id": "gpT8l7T4w2_l"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "dementia_table = Table.read_table('oasis_cross-sectional.csv') # read the csv file into the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XQoBNmjlxDXM",
      "metadata": {
        "id": "XQoBNmjlxDXM"
      },
      "outputs": [],
      "source": [
        "# Reivew the data in the table\n",
        "dementia_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VflTO_cWw8ak",
      "metadata": {
        "id": "VflTO_cWw8ak"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df = pd.read_csv('oasis_cross-sectional.csv') # read the csv file into the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t1NcjcD9xFFC",
      "metadata": {
        "id": "t1NcjcD9xFFC"
      },
      "outputs": [],
      "source": [
        "# Review the data in the dataframe\n",
        "dementia_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1OmVGEy0LaKu",
      "metadata": {
        "id": "1OmVGEy0LaKu"
      },
      "outputs": [],
      "source": [
        "# Review the type to show dataframe from pandas package\n",
        "type(dementia_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OYNVFYFRFjms",
      "metadata": {
        "id": "OYNVFYFRFjms"
      },
      "source": [
        "We see here how to import an external csv file into our current notebook using both libraries. With `pandas` `read_csv()` function, we use `pd.read_csv()` to let Python know we want to use this particular `pandas` function.\n",
        "Notice how there is an extra column of numbers in the DataFrame that results. These numbers are called the index of a DataFrame, and will be useful later in order to select different rows that we are interested in."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zxur8whYFjms",
      "metadata": {
        "id": "zxur8whYFjms"
      },
      "source": [
        "In `pandas`, we have two types of objects: DataFrames and Series. Series are similar to a DataFrame except there is only one column in a Series. You can think of Series as a single column of a DataFrame. Later in this notebook, we will use Series as well as DataFrames. Series come up when we select one column of a DataFrame, apply different functions to a column, etc.\n",
        "\n",
        "You can learn more about DataFrames and Series with this [documentation](https://pandas.pydata.org/pandas-docs/stable/dsintro.html) as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JCtqO2NM5Iqi",
      "metadata": {
        "id": "JCtqO2NM5Iqi"
      },
      "outputs": [],
      "source": [
        "# Another thing to do when you first look at your new data, is to see what info is there\n",
        "# This is possible with .info() after the name of your data frame like so:\n",
        "print(dementia_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2A-T3R5I5edL",
      "metadata": {
        "id": "2A-T3R5I5edL"
      },
      "source": [
        "We have 436 rows (observations) and 12 columns. In the column labeled `Column`, the names of each column are listed and it shows how many non-null values are present, meaning how much data there is. Any difference between this number and the total number of entries (436 shown at the top) indicates there is missing data. The last column `Dtype` tells us what type of data you have in each column. You can see here that many are numbers and have no decimals (`int`) or have decimal values (`float64`). Note that in Pandas, strings are labeled as `object` (first three entries)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ciJmAnj6jli",
      "metadata": {
        "id": "4ciJmAnj6jli"
      },
      "source": [
        "We can see that we do have missing data here. Particularly in the `Delay` column because we only have 20 values. So we are missing 416 (436 - 20) values. If you go back up and review the table, you will see that missing values are labeled with `NaN`, which stands for `Not a Number`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DGzhAjoYFjmt",
      "metadata": {
        "id": "DGzhAjoYFjmt"
      },
      "source": [
        "---\n",
        "### Make a Table/DataFrame\n",
        "If we want to create a new Table or DataFrame from scratch, we can call the respective functions and then specify the columns and the data within each column (where the data is in array/dict format). Some examples from both `datascience` and `pandas` are shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dVkFl_i_Fjmt",
      "metadata": {
        "id": "dVkFl_i_Fjmt"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "# create Table with 2 columns and 3 rows\n",
        "flowers = Table().with_columns(\n",
        "    'Number of petals', make_array(8, 34, 5),\n",
        "    'Name', make_array('lotus', 'sunflower', 'rose')\n",
        ")\n",
        "flowers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RNqkyXC9Fjmt",
      "metadata": {
        "id": "RNqkyXC9Fjmt"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "# create DataFrame with 2 columns and 3 rows\n",
        "flowers_df = pd.DataFrame(data = {'Number of petals': [8, 34, 5], 'Name': ['lotus', 'sunflower', 'rose']})\n",
        "flowers_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YmbcEF8-xbIp",
      "metadata": {
        "id": "YmbcEF8-xbIp"
      },
      "outputs": [],
      "source": [
        "# Note how we have added the data using a new python data type\n",
        "new_type = {'Number of petals': [8, 34, 5], 'Name': ['lotus', 'sunflower', 'rose']}\n",
        "type(new_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_q127mJpaijD",
      "metadata": {
        "id": "_q127mJpaijD"
      },
      "source": [
        "---\n",
        "### Dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6wq5EeoX0Nb-",
      "metadata": {
        "id": "6wq5EeoX0Nb-"
      },
      "source": [
        "Here we have a new type of data structure that we haven't covered in this class. This is called a dictionary. Dictionaries store data in key:value pairs. Also note that we have a new type of brackets or braces that are curly `{ }`\n",
        "\n",
        "<br>\n",
        "\n",
        "In the example above, the key: value pairs are: <br>\n",
        "`{'Number of petals': [8,34,5],` <br>\n",
        "`'Name': ['lotus','sunflower', 'rose']}` <br>\n",
        "The keys are the strings for the column names, and the values are the data that go in the rows of the table. <br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sCVkVI7VZXn4",
      "metadata": {
        "id": "sCVkVI7VZXn4"
      },
      "source": [
        "Dictionaries are structures which can contain multiple data types. For each unique key, the dictionary has one value. Keys can be various data types: strings, numbers, or tuples, while the corresponding values can be any Python object.<br>\n",
        "\n",
        "You **cannot** access values of the dictionary by the indexes (like you can in lists or arrays). But you can access them by the key. Due to this feature dictionaries don't allow duplicated keys.\n",
        "\n",
        "You can also access just the keys or just the indexes by `.keys()` and `.values()` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TN-Ndml5ZiM_",
      "metadata": {
        "id": "TN-Ndml5ZiM_"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary called participant\n",
        "participant = {'name': 'Jon Doe', 'group': 'Control', 'age': 42}\n",
        "print(participant['name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SqzTFVx3al_C",
      "metadata": {
        "id": "SqzTFVx3al_C"
      },
      "outputs": [],
      "source": [
        "# How would you reference the other keys like in the print statement above? try group or age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rDX-VBKpasj4",
      "metadata": {
        "id": "rDX-VBKpasj4"
      },
      "outputs": [],
      "source": [
        "# add new key-value pair to the dictionary\n",
        "participant['ID'] = 'CJD'\n",
        "print(participant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gy9vZyuBa0Ip",
      "metadata": {
        "id": "Gy9vZyuBa0Ip"
      },
      "outputs": [],
      "source": [
        "# method to access keys\n",
        "participant.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UWIWkxBOa18i",
      "metadata": {
        "id": "UWIWkxBOa18i"
      },
      "outputs": [],
      "source": [
        "# method to access values\n",
        "participant.values()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vKhrXJ5HaJ5F",
      "metadata": {
        "id": "vKhrXJ5HaJ5F"
      },
      "source": [
        " To find out more, read the Python [documentation](https://docs.python.org/3/tutorial/datastructures.html#dictionaries). <br>\n",
        "\n",
        "Other examples and [tutorial](https://www.w3schools.com/python/python_dictionaries.asp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wizyU9ziFjmt",
      "metadata": {
        "id": "wizyU9ziFjmt"
      },
      "source": [
        "---\n",
        "### Select Columns\n",
        "In both `datascience` and `pandas` we can select a column or multiple columns, based on what information we want from the data. In `datascience` we use the `select()` function, while in `pandas` we use indexing with brackets `[]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2tnxPBin3WyN",
      "metadata": {
        "id": "2tnxPBin3WyN"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "# select one columns\n",
        "dementia_table.select('Age')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TdJmB1sf3bAd",
      "metadata": {
        "id": "TdJmB1sf3bAd"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "# select multiple columns\n",
        "dementia_table.select('Age','M/F')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DGGr5Ly23rFj",
      "metadata": {
        "id": "DGGr5Ly23rFj"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "# select one column - return Series\n",
        "dementia_df[\"Age\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pVZoeqUo3yPo",
      "metadata": {
        "id": "pVZoeqUo3yPo"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "# select one column - return DataFrame\n",
        "dementia_df[[\"Age\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FX81WVOQ3-mw",
      "metadata": {
        "id": "FX81WVOQ3-mw"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "# select a specific column\n",
        "dementia_df.Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lWHa8-uk4KSP",
      "metadata": {
        "id": "lWHa8-uk4KSP"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "# select multiple columns\n",
        "dementia_df[[\"Age\", \"M/F\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o4qZbT4VMCrc",
      "metadata": {
        "id": "o4qZbT4VMCrc"
      },
      "source": [
        "If you want to view all columns in your dataframe in `pandas` you can also use the following method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dltTu42pMHks",
      "metadata": {
        "id": "dltTu42pMHks"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lvq4R9tfFjmu",
      "metadata": {
        "id": "lvq4R9tfFjmu"
      },
      "source": [
        "We can also use `loc` and `iloc` to select specific columns, which we will introduce in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lM_Ig3mpFjmu",
      "metadata": {
        "id": "lM_Ig3mpFjmu"
      },
      "source": [
        "---\n",
        "### Select Rows\n",
        "In `datascience`, we use `take` in order to select certain rows, based on what row numbers we want to select (0 indexed). With selecting multiple rows, we use the concept of list slicing in order to select a sequence of rows, or even select multiple rows (if the numbers are in an array)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BKTP2yEg7upA",
      "metadata": {
        "id": "BKTP2yEg7upA"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "dementia_table.take(2) # select the row with an index of 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P4NnGHjL7zd1",
      "metadata": {
        "id": "P4NnGHjL7zd1"
      },
      "outputs": [],
      "source": [
        "dementia_table.take(np.arange(1, 3)) # select the rows with index from 1 to 3 - remember, the last # will NOT be included"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U3mH1N_277uL",
      "metadata": {
        "id": "U3mH1N_277uL"
      },
      "outputs": [],
      "source": [
        "dementia_table.take[0, 3, 4] # select the rows with index 0, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oJ3LGMAj8GPS",
      "metadata": {
        "id": "oJ3LGMAj8GPS"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df[0:3] # select the rows with index from 0 to 3 (not including 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QUVCeKVQ8TKa",
      "metadata": {
        "id": "QUVCeKVQ8TKa"
      },
      "source": [
        "What we did above is called *slicing*. Like we learned about what to put into `np.arange`, the input you can enter has a similar format. For example, the structure looks like this: <br>\n",
        "`[start_index : end_index : step]` <br>\n",
        "\n",
        "Note that here we use a colon `:` instead of a comma `,` to separate the input values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5nnCZLAd85rN",
      "metadata": {
        "id": "5nnCZLAd85rN"
      },
      "source": [
        "In our example, note that slicing also only selects the values up to the `end_index`, but does not include that value. That is why we got rows from 0 to 2, but not the third. Remember we index starting from 0. <br>\n",
        "Also note that we did not enter a third argument/input to slice. We omitted `step`, which has a default value of 1 and does not need to be entered if that is the option you'd like to use."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4gqQSF9tFjmv",
      "metadata": {
        "id": "4gqQSF9tFjmv"
      },
      "source": [
        "---\n",
        "#### loc and iloc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fhSReCC7Fjmv",
      "metadata": {
        "id": "fhSReCC7Fjmv"
      },
      "source": [
        "With `pandas`, we can use `loc` and `iloc` to select certain rows or columns from a DataFrame - all at once - making it a powerful tool. <br>\n",
        "`loc` (stands for `loc`ation) gets rows or columns with particular labels from the index. <br>\n",
        "`iloc` (stands for `i`nteger `loc`ation) gets rows or columns at particular positions in the index (so it only takes integers). <br><br>\n",
        "With both of these, we index using brackets and specify which rows and columns we want to select based on `[row, column]`. <br>\n",
        "Note: if we have just `:` for either row or column, this means that we select all of it (based on if it is in the row or column section of the brackets). An example is shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baCTaAsafw-l",
      "metadata": {
        "id": "baCTaAsafw-l"
      },
      "source": [
        "Here is a helpful image from this [website](https://www.shanelynn.ie/pandas-iloc-loc-select-rows-and-columns-dataframe/)\n",
        "\n",
        "![](pd_iloc.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2W_dAKDWgihH",
      "metadata": {
        "id": "2W_dAKDWgihH"
      },
      "outputs": [],
      "source": [
        "dementia_df.loc[:,'Age'] # select all rows but only the column Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8J299h4RgnBl",
      "metadata": {
        "id": "8J299h4RgnBl"
      },
      "outputs": [],
      "source": [
        "dementia_df.loc[:,['Age', 'M/F']] # select all rows but only the Age and M/F columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M8G8P43fgtzI",
      "metadata": {
        "id": "M8G8P43fgtzI"
      },
      "outputs": [],
      "source": [
        "dementia_df.iloc[1:3,0:3] # select the rows with index from 1 to 3 (not including 3) and columns in the positions of 0 to 3 (not including 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6gjN-EQQFjmv",
      "metadata": {
        "id": "6gjN-EQQFjmv"
      },
      "source": [
        "---\n",
        "### Rename Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mWwzxQJdFjmv",
      "metadata": {
        "id": "mWwzxQJdFjmv"
      },
      "source": [
        "In the `datascience` package, we can rename a column or multiple columns. We may want to do this when we update a column to make the title more specific. We also need to make sure that the new column name is not the same as any other existing columns (so we do not have two columns with the same name as this will error). We do this with the `relabeled()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UR4ptWWNJ23x",
      "metadata": {
        "id": "UR4ptWWNJ23x"
      },
      "outputs": [],
      "source": [
        "dementia_table.relabeled('Educ', 'Education') # rename the Educ column as Education"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s9uFCVFyKPzw",
      "metadata": {
        "id": "s9uFCVFyKPzw"
      },
      "outputs": [],
      "source": [
        "dementia_table.relabeled(['Educ', 'SES'], ['Education', 'Socioeconmoic Status']) # rename the Educ column as Education and SES and Socioeconomic Status"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "blvTDaduFjmw",
      "metadata": {
        "id": "blvTDaduFjmw"
      },
      "source": [
        "In `pandas` we can use a similar function called `rename()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mPhYhilsIZQD",
      "metadata": {
        "id": "mPhYhilsIZQD"
      },
      "outputs": [],
      "source": [
        "dementia_df.rename(columns = {'Age': 'New Age'})  # rename the Age column as New Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ax1hSM-IvaO",
      "metadata": {
        "id": "6ax1hSM-IvaO"
      },
      "outputs": [],
      "source": [
        "dementia_df.rename(columns={'SES': 'Socioeconomic Status', 'Educ': 'Education'}) # rename SES as Socioeconomic Status and Educ as Education"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_Ciuv8UCFjmx",
      "metadata": {
        "id": "_Ciuv8UCFjmx"
      },
      "source": [
        "---\n",
        "### Where/Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CZJqak_vFjmx",
      "metadata": {
        "id": "CZJqak_vFjmx"
      },
      "source": [
        "In `datascience` there is a function called `where` which creates a copy of a table with only the rows that match some condition. To filter out a DataFrame by its contents in `pandas`, we need to use boolean (`True` or `False`) expressions in order to select the rows we want to keep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kxkc21R3JtAI",
      "metadata": {
        "id": "Kxkc21R3JtAI"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "dementia_table.where(\"Age\", are.above(75)) # select/filter rows so the Age is above 75"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YNazEB9rFjmx",
      "metadata": {
        "id": "YNazEB9rFjmx"
      },
      "source": [
        "We want to keep the rows that have a price that is greater than 4. We can first create a boolean array, which will assign a `True` or `False` value to each row based on if it satisfies the condition we give it. We can then index this array into our original array and only the values that are `True` will be returned in a DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mNnlq0TxLXuc",
      "metadata": {
        "id": "mNnlq0TxLXuc"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "boolean_array = dementia_df[\"Age\"] > 75 # create a boolean array saying if the Age is greater than 75\n",
        "boolean_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hkODUjsFLcAq",
      "metadata": {
        "id": "hkODUjsFLcAq"
      },
      "outputs": [],
      "source": [
        "dementia_df[boolean_array] # apply boolean array to DataFrame and filter the rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JXJzzIXwM95P",
      "metadata": {
        "id": "JXJzzIXwM95P"
      },
      "source": [
        "We can also do this all in one step as shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T7yYsmUlLgWI",
      "metadata": {
        "id": "T7yYsmUlLgWI"
      },
      "outputs": [],
      "source": [
        "# All in one step\n",
        "dementia_df[dementia_df[\"Age\"] > 75] # filter the DataFrame based on Age greater than 75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5I1Nz-vLsJH",
      "metadata": {
        "id": "c5I1Nz-vLsJH"
      },
      "outputs": [],
      "source": [
        "# Note the above created a new dataframe and did not replace our original- all data is still here\n",
        "dementia_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VeXvpgT-Fjmy",
      "metadata": {
        "id": "VeXvpgT-Fjmy"
      },
      "source": [
        "Sometimes we want to filter by multiple different conditions. In `pandas` we can do this using parentheses and a symbol indicating if we want both conditions to be satisfied (and) or at least one to be satisfied (or). The format is:\n",
        "\n",
        "`df[(condition1) & (condition2)]`\n",
        "\n",
        "or\n",
        "\n",
        "`df[(condition1) | (condition2)]`\n",
        "\n",
        "Note: `&` is different from `and`\n",
        "also `|` is different from `or`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qjRChSTPMlCC",
      "metadata": {
        "id": "qjRChSTPMlCC"
      },
      "outputs": [],
      "source": [
        "dementia_df[(dementia_df[\"Age\"] > 30) & (dementia_df[\"Age\"] < 75)] # filter the DataFrame based on Age greater than 30 and less than 75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bm3j7ZN_WwMS",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "bm3j7ZN_WwMS",
        "outputId": "455425dc-6ef1-41ab-9b2c-45ce32b527a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
              "  <h4 class=\"alert-heading\">Task</h4>\n",
              "You run an experiment with two groups: control (`control`) and treatment (`treatment`). You want to filter out some participants from the treatment group who don‚Äôt meet the minimum BMI criteria (BMI should be equal to or greater than 15). <br>\n",
              "Does this participant meet this criterion?\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Task\n",
        "from IPython.display import HTML\n",
        "\n",
        "alert_info = '''\n",
        "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
        "  <h4 class=\"alert-heading\">Task</h4>\n",
        "You run an experiment with two groups: control (`control`) and treatment (`treatment`). You want to filter out some participants from the treatment group who don‚Äôt meet the minimum BMI criteria (BMI should be equal to or greater than 15). <br>\n",
        "Does this participant meet this criterion?\n",
        "</div>\n",
        "'''\n",
        "\n",
        "display(HTML('<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">'))\n",
        "display(HTML(alert_info))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TZ9YJy5_YPG6",
      "metadata": {
        "id": "TZ9YJy5_YPG6"
      },
      "outputs": [],
      "source": [
        "# Replace the code where you see ...\n",
        "age = 30\n",
        "group = 'control'\n",
        "BMI = 20\n",
        "\n",
        "condition = (group ... \"treatment\") ... ( .... >= 15)\n",
        "print(condition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "MilwDYeZW_tE",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "MilwDYeZW_tE",
        "outputId": "c4cfc9bf-0e1e-4e82-b5bc-cd68f1a05050"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
              "  <h4 class=\"alert-heading\">Task</h4>\n",
              "Now you want to be more sophisticated (for whatever reason). You update your criteria for the treatment group. You want to keep the participant if they are older than 40 or their BMI equals or greater than 15.<br>\n",
              "Does this participant fit the updated conditions?\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Task\n",
        "from IPython.display import HTML\n",
        "\n",
        "alert_info = '''\n",
        "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
        "  <h4 class=\"alert-heading\">Task</h4>\n",
        "Now you want to be more sophisticated (for whatever reason). You update your criteria for the treatment group. You want to keep the participant if they are older than 40 or their BMI equals or greater than 15.<br>\n",
        "Does this participant fit the updated conditions?\n",
        "</div>\n",
        "'''\n",
        "\n",
        "display(HTML('<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">'))\n",
        "display(HTML(alert_info))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OcH4uZFZY18A",
      "metadata": {
        "id": "OcH4uZFZY18A"
      },
      "outputs": [],
      "source": [
        "# Replace the code where you see ...\n",
        "age = 30\n",
        "group = 'control'\n",
        "BMI = 20\n",
        "\n",
        "condition = ((BMI ... 15) ... (age ... 40)) ... (group ... \"treatment\")\n",
        "print(condition)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_2slCB1pFjmy",
      "metadata": {
        "id": "_2slCB1pFjmy"
      },
      "source": [
        "---\n",
        "### Sort, Group, Pivot\n",
        "#### Sort\n",
        "We can sort values similarly in Tables and DataFrames - using a function and what column we want to sort by."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J2Eh4fN_slt7",
      "metadata": {
        "id": "J2Eh4fN_slt7"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "dementia_table.sort('Age') # sort the table by Age column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q8akQLEasuWq",
      "metadata": {
        "id": "Q8akQLEasuWq"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df.sort_values('Age') # sort DataFrame by Age column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pRHIHhKttDKV",
      "metadata": {
        "id": "pRHIHhKttDKV"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df.sort_values('Age', ascending=False) # sort DataFrame by Age column"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BjVkXVohFjmy",
      "metadata": {
        "id": "BjVkXVohFjmy"
      },
      "source": [
        "If we want to specify whether we sort in ascending order or descending order. In `datascience` we can do this with the `descending` parameter, and setting it equal to `True` or `False`. <br> In `pandas` we can use the `ascending` parameter and set this equal to `True` or `False`. By default, the column sorts in ascending order.\n",
        "\n",
        "#### Group\n",
        "In both `datascience` and `pandas` we can use group functions that allow us to group records of our data into buckets. You can think of grouping as splitting the dataset data into buckets. Then you can call \"aggregate\" functions (`mean`, `sum`, `max`, `min`, etc) on these buckets to find these values per bucket (which can lead to interesting analysis)!\n",
        "\n",
        "Let's say that we want to group by flavor of ice cream and see what the total sum is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mUljyicotURs",
      "metadata": {
        "id": "mUljyicotURs"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "dementia_table.select(['Age', 'M/F']).group('M/F', collect=np.average) # select the Age and M/F columns and then group by M/F and find the average Age per group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2BQ-Zm4zttVw",
      "metadata": {
        "id": "2BQ-Zm4zttVw"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df[['Age', 'M/F']].groupby('M/F').mean() # select the Age and M/F columns and then group by M/F and find the average Age per group"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DDjnsvIEBrFK",
      "metadata": {
        "id": "DDjnsvIEBrFK"
      },
      "source": [
        "In this example, we want to see the **minimum** estimated total intracranial volume (eTIV) and **average** normalized whole-brain volume (nWBV) for each gender and clinical dementia rating (CDR). The following line of code might seem complicated, but run it to see the output and then we will break down the steps afterward.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dKK0mJBJB2d5",
      "metadata": {
        "id": "dKK0mJBJB2d5"
      },
      "outputs": [],
      "source": [
        "dementia_df.groupby([\"CDR\", \"M/F\"]).agg({\"eTIV\": \"min\", \"nWBV\": \"mean\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HMHn2aGSB_JJ",
      "metadata": {
        "id": "HMHn2aGSB_JJ"
      },
      "source": [
        "1. `groupby` a list of column names. We only used one column above, but you can add more than one like we did here.\n",
        "2. After we use `groupby`, we apply the aggregation method `.agg()` and specify a dictionary in a following way: `{column_name: aggregation function}`. We applied multiple functions at once on different columns.\n",
        "\n",
        "**Notice**:  If you wanted to apply multiple functions on the same column you could specify a list, for example, `{\"eTIV: ['min','max']}`. Try it out!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pVasNqflFjmz",
      "metadata": {
        "id": "pVasNqflFjmz"
      },
      "source": [
        "#### Pivot\n",
        "We can create pivot tables in both `datascience` and `pandas` using different functions and specifying columns, index, values, and the collect/aggregate function acting on the values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oKtB0FHgvSGM",
      "metadata": {
        "id": "oKtB0FHgvSGM"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "dem_pivot = dementia_table.pivot(columns = 'M/F', rows = 'Age', values = 'MMSE', collect=np.mean) # create a pivot table with Flavors and Color and sum prices for corresponding entries\n",
        "sorted = dem_pivot.sort('Age',descending = True) # sorted because most values are filled in for higher Ages, younger participants have lots of NaNs\n",
        "sorted.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62j6vF53xGPi",
      "metadata": {
        "id": "62j6vF53xGPi"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df.pivot_table(values='MMSE', index=['Age'], columns=['M/F'], aggfunc=np.average) # create a pivot table with Flavors and Color and sum prices for corresponding entries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Df4ukRjEFjmz",
      "metadata": {
        "id": "Df4ukRjEFjmz"
      },
      "source": [
        "Note: We have `NaN` as values in our above table because `pandas` cannot find appropriate values for those specific combinations of rows and columns. If we want to replace these values with 0, we can use `fillna(0)` on the resulting pivot table.\n",
        "\n",
        "Don't be alarmed by these `NaN` values! This is something to note about real data, often times the data is not cleaned already and null values are very common. They may even be important in your exploration of the data, the number of null values you have and where they occur could be important!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fl4mm7C7Fjmz",
      "metadata": {
        "id": "Fl4mm7C7Fjmz"
      },
      "source": [
        "---\n",
        "### Visualizing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cXkxcK3lS0Z8",
      "metadata": {
        "id": "cXkxcK3lS0Z8"
      },
      "source": [
        "\n",
        " **Seaborn** is a plotting package that works with matplotlib to more easily adjust the aesthetics of plots.\n",
        "\n",
        "\n",
        "Read the [introduction](https://seaborn.pydata.org/tutorial/introduction.html) to the package, up to and including the **Statistical estimation section**. After reading, return to the notebook and continue exploring this package with the guided prompts below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WTjBlgQFbzae",
      "metadata": {
        "id": "WTjBlgQFbzae"
      },
      "source": [
        "We already imported it at the beginning as: <br>\n",
        "`import seaborn as sns` <br>\n",
        "We use `sns` as the abbreviation because just like `numpy` is `np`, this is commonly used.<br> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1qstAT1LcRNC",
      "metadata": {
        "id": "1qstAT1LcRNC"
      },
      "source": [
        "#### Barplots\n",
        "Let's start by working with barplots. <br>\n",
        "Seaborn documentation:\n",
        "https://seaborn.pydata.org/generated/seaborn.barplot.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pFRRnBtufTKW",
      "metadata": {
        "id": "pFRRnBtufTKW"
      },
      "source": [
        "You only need a few options at minimum to create a barplot.<br>\n",
        "\n",
        "\n",
        "1.   The data to use: `data = dataframe_name`\n",
        "2.   x values based on a column name from the dataframe: `\"CDR\"`\n",
        "3.   y values based on a column name from the dataframe: `\"Age\"`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QODbC8p0fYW_",
      "metadata": {
        "id": "QODbC8p0fYW_"
      },
      "outputs": [],
      "source": [
        "# Let's plot CDR (x-axis) by Age (y-axis)\n",
        "sns.barplot(\n",
        "    data=dementia_df,          # start by identifying our dataframe\n",
        "    x=\"CDR\",                   # column name from our dataset to use for x-values\n",
        "    y=\"Age\");                  # column name from our dataset to use for y-values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GKPDhFPxfxFY",
      "metadata": {
        "id": "GKPDhFPxfxFY"
      },
      "source": [
        "You can see that it automatically adds a few things for you. This includes labels for your axes based on the column names that were used. It also adds errorbars based on the 95% confidence interval that it determines based on the data (you don't see this part- it just does it). It chooses a default color pallete here, so we have some interesting (bright!) color choices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "du91HRnncpEV",
      "metadata": {
        "id": "du91HRnncpEV"
      },
      "outputs": [],
      "source": [
        "# Let's adjust our plot and add a few things - just run this cell\n",
        "sns.barplot(\n",
        "    data=dementia_df,          # start by identifying our dataframe\n",
        "    x=\"CDR\",                   # column name from our dataset to use for x-values\n",
        "    y=\"Age\",                   # column name from our dataset to use for y-values\n",
        "    errorbar=\"sd\",             # always a good idea to add error bars to our mean values\n",
        "    color=\"royalblue\")         # specify a color- many options!\n",
        "plt.title(\"Age (Mean ¬± SD)\");  # this is from matplotlib and adds text for a title\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lUBpPruGdsyD",
      "metadata": {
        "id": "lUBpPruGdsyD"
      },
      "outputs": [],
      "source": [
        "# Similar plot, but:\n",
        "# add Biological Sex (M/F) as another grouping factor- *hue* option below\n",
        "\n",
        "sns.barplot(                   # this is all part of the seaborn\n",
        "    data=dementia_df,          # start by identifying our dataframe\n",
        "    x=\"CDR\",                   # column name from our dataset to use for x-values\n",
        "    y=\"Age\",                   # column name from our dataset to use for y-values\n",
        "    hue=\"M/F\",                 # this is optional- we can color code by another variable\n",
        "    errorbar=\"sd\",             # always a good idea to add error bars to our mean values\n",
        "    color=\"lightblue\")         # lots of options for colors\n",
        "plt.title(\"CDR Score By Age (Mean ¬± SD)\");  # this is from matplotlib and adds text for a title\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0);  # you don't need to know this, but it puts the legend outside the box so it doesn't overlap with data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "30V55LIhXX_6",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "30V55LIhXX_6",
        "outputId": "cf436437-e08d-49aa-e516-5f061502cbe3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
              "  <h4 class=\"alert-heading\">Task</h4>\n",
              "Adjust the code for the plotting below based on what was given above. Make sure to pay attention to which variables you are plotting. Each one is different!\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Task\n",
        "from IPython.display import HTML\n",
        "\n",
        "alert_info = '''\n",
        "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
        "  <h4 class=\"alert-heading\">Task</h4>\n",
        "Adjust the code for the plotting below based on what was given above. Make sure to pay attention to which variables you are plotting. Each one is different!\n",
        "</div>\n",
        "'''\n",
        "\n",
        "display(HTML('<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">'))\n",
        "display(HTML(alert_info))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dQhsm07IFd6C",
      "metadata": {
        "id": "dQhsm07IFd6C"
      },
      "outputs": [],
      "source": [
        "# Now use the code above, but plot CDR (x-axis) by Years of Education (y-axis)\n",
        "# Keep Biological Sex (M/F) as another grouping factor- include *hue* option\n",
        "\n",
        "sns.barplot(                   # this is all part of the seaborn\n",
        "...                            # add several lines of code like above here\n",
        ")\n",
        "plt.title();                   # adjust your title too!\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0);  # you don't need to know this, but it puts the legend outside the box so it doesn't overlap with data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jwRlxXWgFo4K",
      "metadata": {
        "id": "jwRlxXWgFo4K"
      },
      "outputs": [],
      "source": [
        "# Now plot CDR (x-axis) by Socioeconomic Status (y-axis)\n",
        "# Keep Biological Sex (M/F) as another grouping factor- include *hue* option\n",
        "\n",
        "sns.barplot(                   # this is all part of the seaborn\n",
        "...                            # add several lines of code like above here\n",
        ")\n",
        "plt.title();                   # adjust your title too!\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0);  # you don't need to know this, but it puts the legend outside the box so it doesn't overlap with data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "txtpglOoFD85",
      "metadata": {
        "id": "txtpglOoFD85"
      },
      "outputs": [],
      "source": [
        "# Now plot CDR (x-axis) by Mini-Mental State Exam Score (y-axis)\n",
        "# Keep Biological Sex (M/F) as another grouping factor- include *hue* option\n",
        "\n",
        "sns.barplot(                   # this is all part of the seaborn\n",
        "...                            # add several lines of code like above here\n",
        ")\n",
        "plt.title();                   # adjust your title too!\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0);  # you don't need to know this, but it puts the legend outside the box so it doesn't overlap with data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vXI4j4O-GjSa",
      "metadata": {
        "id": "vXI4j4O-GjSa"
      },
      "source": [
        "Here's an example of how you could automate the creation of each plot from above and make them 'subplots' of your figure using a `for` loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yLSI6wMwGiNT",
      "metadata": {
        "id": "yLSI6wMwGiNT"
      },
      "outputs": [],
      "source": [
        "columns_to_plot = [\"Age\", \"Educ\", \"SES\", \"MMSE\"]\n",
        "\n",
        "plt.figure(figsize=(10,7), facecolor=\"white\")\n",
        "\n",
        "for (i, colname) in enumerate(columns_to_plot):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    sns.barplot(\n",
        "        data=dementia_df, x=\"CDR\", y=colname,\n",
        "        hue=\"M/F\", errorbar=\"sd\", color=\"lightblue\")\n",
        "    plt.title(f\"{colname} (Mean ¬± SD)\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0);  # you don't need to know this, but it puts the legend outside the box so it doesn't overlap with data\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VkUilmvvG5oS",
      "metadata": {
        "id": "VkUilmvvG5oS"
      },
      "source": [
        "Here we could also use `groupby` to help us grab the actual numbers that appear in the plot. This is a good idea to check that things match when you are working with your code. The values should be what you expect based on the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FEo9-cRHG1fB",
      "metadata": {
        "id": "FEo9-cRHG1fB"
      },
      "outputs": [],
      "source": [
        "# Calculate summary statistics to review and compare to plot\n",
        "print(\"Summary statistics:\")\n",
        "\n",
        "# get the numerical values\n",
        "summary_stats = dementia_df.groupby(by=[\"CDR\", \"M/F\"]).agg(\n",
        "    {\"ID\": \"count\", \"Age\": [\"mean\", \"std\"], \"Educ\": [\"mean\", \"std\"],\n",
        "     \"SES\": [\"mean\", \"std\"], \"MMSE\": [\"mean\", \"std\"]}).round(2)\n",
        "\n",
        "display(summary_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "POfbTEF4Xjl7",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "POfbTEF4Xjl7",
        "outputId": "21340c82-13a9-47ed-e13f-da65fc488fb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
              "  <h4 class=\"alert-heading\">Task</h4>\n",
              "Answer the following question: <br>\n",
              "Which of the following statements is correct based on the data in the table and the plots we made above: <br><br>\n",
              "\n",
              "1.   There are 2 people in the dataset with moderate dementia and they are both male.<br>\n",
              "2.   Healthy controls (no dementia) have more variability in MMSE score compared to patients with dementia.<br>\n",
              "3.   Age and dementia status (CDR) are positively correlated.<br>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Task\n",
        "from IPython.display import HTML\n",
        "\n",
        "alert_info = '''\n",
        "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
        "  <h4 class=\"alert-heading\">Task</h4>\n",
        "Answer the following question: <br>\n",
        "Which of the following statements is correct based on the data in the table and the plots we made above: <br><br>\n",
        "\n",
        "1.   There are 2 people in the dataset with moderate dementia and they are both male.<br>\n",
        "2.   Healthy controls (no dementia) have more variability in MMSE score compared to patients with dementia.<br>\n",
        "3.   Age and dementia status (CDR) are positively correlated.<br>\n",
        "</div>\n",
        "'''\n",
        "\n",
        "display(HTML('<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">'))\n",
        "display(HTML(alert_info))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EeNXUmW_Hnbm",
      "metadata": {
        "id": "EeNXUmW_Hnbm"
      },
      "source": [
        "*Type the number for your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XF8NPNlvHyHN",
      "metadata": {
        "id": "XF8NPNlvHyHN"
      },
      "source": [
        "#### Scatterplots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wVtNFrYvLXYy",
      "metadata": {
        "id": "wVtNFrYvLXYy"
      },
      "source": [
        "The nice thing about the seaborn package is that it makes it easy to add or modify a simple scatterplot. This helps to create nice visualizations! <br>\n",
        "`seaborn` scatterplots: https://seaborn.pydata.org/generated/seaborn.scatterplot.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TFRdbyrcLyv_",
      "metadata": {
        "id": "TFRdbyrcLyv_"
      },
      "source": [
        "We will start by plotting the relationship between estimated total intracranial volume (`eTIV`) and normalized whole-brain volume (`nWBV`). <br>\n",
        "\n",
        "Again, you only need a few basic things to define your plot: `dataframe`,`x-values`, and `y-values`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i1BE5KlWLgdb",
      "metadata": {
        "id": "i1BE5KlWLgdb"
      },
      "outputs": [],
      "source": [
        "# Let's start simple like we've already been doing alot in this class\n",
        "# Plot the relationship between eTIV and nWBV\n",
        "sns.scatterplot(\n",
        "    data=dementia_df,\n",
        "    x=\"eTIV\",\n",
        "    y=\"nWBV\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K2fMNCQuMCXZ",
      "metadata": {
        "id": "K2fMNCQuMCXZ"
      },
      "source": [
        "But what if we also want to look by sex (`M/F`) like we did above in our barplots. We can easily add to our plot! <br>\n",
        "\n",
        "To do this, we use the `hue` option and you can set the color `palette` that you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QuStljdzMIgH",
      "metadata": {
        "id": "QuStljdzMIgH"
      },
      "outputs": [],
      "source": [
        "# Now add hue and color palette we want\n",
        "sns.scatterplot(\n",
        "    data=dementia_df,\n",
        "    x=\"eTIV\",\n",
        "    y=\"nWBV\",\n",
        "    hue = \"M/F\",                          # we add a hue to group our data by this column from our data\n",
        "    palette = \"magma\");                   # choose colors for our points\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vcpma2RaMWT-",
      "metadata": {
        "id": "Vcpma2RaMWT-"
      },
      "source": [
        "We can also even add another variable that changes the size of the dots based on the atlas scaling factor (`ASF`) from our data.<br>\n",
        "This is the `size` option. I've additionally added some values to make the sizes more apparent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VTmuRLkkMfL3",
      "metadata": {
        "id": "VTmuRLkkMfL3"
      },
      "outputs": [],
      "source": [
        "# Add size - review the legend to see how this relates to the values in the column we selected\n",
        "sns.scatterplot(\n",
        "    data=dementia_df,\n",
        "    x=\"eTIV\",\n",
        "    y=\"nWBV\",\n",
        "    hue=\"M/F\",\n",
        "    size = 'ASF',                       # add another variable to group our data by- we adjust size based on value of this column\n",
        "    sizes=(20, 200),\n",
        "    palette=\"magma\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecPOtcOIMloD",
      "metadata": {
        "id": "ecPOtcOIMloD"
      },
      "source": [
        "And finally, if want to add one more option to our plot, we can also split the plots into separate panels (columns) according to the `CDR`. <br>\n",
        "Note that we do have to switch to a different plot type, and it is similar to `scatterplot` but it has more options than this one! <br>\n",
        "\n",
        "This is called `relplot` for relative plot. You can plot the relationships between many variables of interest like shown below.<br> <br>\n",
        "\n",
        "`seaborn relplot` documentation: https://seaborn.pydata.org/generated/seaborn.relplot.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PrSwwJWcIGva",
      "metadata": {
        "id": "PrSwwJWcIGva"
      },
      "outputs": [],
      "source": [
        "sns.relplot(\n",
        "    data=dementia_df,\n",
        "    x=\"eTIV\",\n",
        "    y=\"nWBV\",\n",
        "    col=\"CDR\",          # split by columns by group\n",
        "    hue=\"M/F\",          # color points according to the group\n",
        "    size=\"ASF\",         # change the size of a point according to the value\n",
        "    sizes=(5, 500),     # scale of the points\n",
        "    palette = 'magma',  # set your color\n",
        "    col_wrap=2          # split to two columns\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1yYLGrsuX4c8",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "1yYLGrsuX4c8",
        "outputId": "6a842443-c153-4d97-ecbe-94036b782f8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
              "  <h4 class=\"alert-heading\">Task</h4>\n",
              "Answer the following question: <br>\n",
              "Based on the plots above, which is true? <br><br>\n",
              "\n",
              "1.   There is a strong positive relationship between eTIV and nWBV among different groups <br>\n",
              "2.   On average, females have greater total intracranial volume <br>\n",
              "3.  On average, values of the atlas scaling factor (ASF) decrease as the estimated total intracranial volume (eTIV) increases <br>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Task\n",
        "from IPython.display import HTML\n",
        "\n",
        "alert_info = '''\n",
        "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
        "  <h4 class=\"alert-heading\">Task</h4>\n",
        "Answer the following question: <br>\n",
        "Based on the plots above, which is true? <br><br>\n",
        "\n",
        "1.   There is a strong positive relationship between eTIV and nWBV among different groups <br>\n",
        "2.   On average, females have greater total intracranial volume <br>\n",
        "3.  On average, values of the atlas scaling factor (ASF) decrease as the estimated total intracranial volume (eTIV) increases <br>\n",
        "</div>\n",
        "'''\n",
        "\n",
        "display(HTML('<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">'))\n",
        "display(HTML(alert_info))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DtwZNgsQKS_g",
      "metadata": {
        "id": "DtwZNgsQKS_g"
      },
      "source": [
        "*Type the number for your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_a8x_odiTQ4I",
      "metadata": {
        "id": "_a8x_odiTQ4I"
      },
      "source": [
        "This demonstrates that there may be multiple ways (`scatterplot` vs. `relplot`) to use functions within packages to produce plots and visualize data!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wj9OUqq7NLe6",
      "metadata": {
        "id": "Wj9OUqq7NLe6"
      },
      "source": [
        "#### Histograms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shsP5i4vkaVu",
      "metadata": {
        "id": "shsP5i4vkaVu"
      },
      "source": [
        "The final plot type we will review will be histograms. We've been using these frequently to visualize the results of our simulations during hypothesis testing.\n",
        "\n",
        "`seaborn` histplot: https://seaborn.pydata.org/generated/seaborn.histplot.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc-Dr0lMNLOU",
      "metadata": {
        "id": "fc-Dr0lMNLOU"
      },
      "outputs": [],
      "source": [
        "# Create a simple plot of the count (frequency) of Age of participants in our sample\n",
        "sns.histplot(\n",
        "    data=dementia_df,\n",
        "    x =\"Age\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qXRmz5boQgLO",
      "metadata": {
        "id": "qXRmz5boQgLO"
      },
      "outputs": [],
      "source": [
        "# What if we try to also plot by M/F?\n",
        "# Notice this is a little harder to tell because the proportions are overlaid\n",
        "sns.histplot(\n",
        "    data=dementia_df,\n",
        "    x =\"Age\",\n",
        "    hue = \"M/F\",                  # try to separate by this grouping variable\n",
        "    stat = \"proportion\");         # added another option to demonstrate we can change this to proportion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xZ_r-eGfRSH2",
      "metadata": {
        "id": "xZ_r-eGfRSH2"
      },
      "outputs": [],
      "source": [
        "# Let's try this another way\n",
        "sns.histplot(\n",
        "    data=dementia_df,\n",
        "    x =\"Age\",\n",
        "    hue = \"M/F\",\n",
        "    multiple = \"dodge\",             # This option separates out our data better for visualizing\n",
        "    stat = \"proportion\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vALj3ahclXeN",
      "metadata": {
        "id": "vALj3ahclXeN"
      },
      "source": [
        "Above we used the option called `dodge`. This is a common option if you are trying to show your data but don't want overlap. For example, if you show all your participants as dots and some overlap, it may be hard to see how many there are or other important variables you want to demonstrate with your data. You can use `dodge` as a way to shift them slightly so there is less overlap. They will still be plotted at the correct location on the graph for the variables of interest, they are usually just moved in a direction that does not meaningfully change the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MVKZ0XdNFxba",
      "metadata": {
        "id": "MVKZ0XdNFxba"
      },
      "source": [
        "For all of the plots above, there are many different parameters you can play around with (color, size, orientation, figure size, axis labels, title, etc). Above are the basic implementations of these graphs but we recommend looking through the documentation and seeing how you can change different aspects of it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aiQ9-B2jFjm0",
      "metadata": {
        "id": "aiQ9-B2jFjm0"
      },
      "source": [
        "If you were wondering, you can also create all of these types of plots with `pandas`.\n",
        "\n",
        "`pandas` barplots: https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.plot.bar.html\n",
        "\n",
        "`pandas` histograms: https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.hist.html\n",
        "\n",
        "`pandas` scatterplots: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.scatter.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1hIE0EI8Fjm1",
      "metadata": {
        "id": "1hIE0EI8Fjm1"
      },
      "source": [
        "---\n",
        "### Calculate the number of columns\n",
        "In `datascience`, calculating the number of columns (or rows) requires a simple call using our Table, either `num_columns` or `num_rows`. With `pandas`, there are two ways to get the number of columns and rows. The `len` function can be used on a part of the DataFrame, or the `shape` function can be used. The `shape` function returns both the number of rows and the number of columns so based on what we want, we will have to select it using indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IFxUXVxLFjm2",
      "metadata": {
        "id": "IFxUXVxLFjm2"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "dementia_table.num_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JAlOQZIaFjm2",
      "metadata": {
        "id": "JAlOQZIaFjm2"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "len(dementia_df.columns) # find the length of the list of column names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o85JvKIGAyRN",
      "metadata": {
        "id": "o85JvKIGAyRN"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df.shape # gives both row, column lengths. output is always in the order of (row, column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tp69dEWyAvXV",
      "metadata": {
        "id": "Tp69dEWyAvXV"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df.shape[1] # select the column part of shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fWaWg_UpFjm2",
      "metadata": {
        "id": "fWaWg_UpFjm2"
      },
      "source": [
        "---\n",
        "### Calculate the number of rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l3kwKZjWFjm2",
      "metadata": {
        "id": "l3kwKZjWFjm2"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "dementia_table.num_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Kdmx6rcFjm2",
      "metadata": {
        "id": "1Kdmx6rcFjm2"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "len(dementia_df) # number of rows in the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GcDqKRudA9y6",
      "metadata": {
        "id": "GcDqKRudA9y6"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df.shape[0] # select the row part of shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pa_sW_k-Fjm2",
      "metadata": {
        "id": "pa_sW_k-Fjm2"
      },
      "source": [
        "---\n",
        "### Apply\n",
        "In both libraries, we have a function called `apply`, which we use to apply a function on a certain column and all its elements. <br>Note: in `pandas`, apply works on a Series (since this is essentially a single column of a DataFrame)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1BRzYrDTfo1",
      "metadata": {
        "id": "e1BRzYrDTfo1"
      },
      "outputs": [],
      "source": [
        "# Let's write our own function that takes the input of the 'M/F' column and converts it to a number\n",
        "def convert_str_to_num(x):\n",
        "    if x == 'M':\n",
        "      return 1\n",
        "    elif x == 'F':\n",
        "      return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D-NiV5ekU9L9",
      "metadata": {
        "id": "D-NiV5ekU9L9"
      },
      "outputs": [],
      "source": [
        "# datascience- apply the function\n",
        "dementia_table.apply(convert_str_to_num, \"M/F\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9HjF3uhVE6N",
      "metadata": {
        "id": "b9HjF3uhVE6N"
      },
      "outputs": [],
      "source": [
        "# Compare the output to the original\n",
        "dementia_table.column('M/F')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2FThsg6cFjm2",
      "metadata": {
        "id": "2FThsg6cFjm2"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "dementia_df[\"M/F\"].apply(convert_str_to_num, \"M/F\") # apply our function to the column M/F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u-_b8O-zFjm3",
      "metadata": {
        "id": "u-_b8O-zFjm3"
      },
      "source": [
        "Above we see that we get the converted values returned to us. If we wanted to change the column in the original Table/DataFrame, we would set the expression above equal to the column/series so that the change is made and saved in the original.\n",
        "\n",
        "For example:\n",
        "\n",
        "`\n",
        "dementia_table = dementia_table.apply(convert_str_to_num, \"M/F\")\n",
        "`\n",
        "\n",
        "or\n",
        "\n",
        "`\n",
        "dementia_df[\"M/F\"] = dementia_df[\"M/F\"].apply(convert_str_to_num, \"M/F\")\n",
        "`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1A8ofWjLFjm3",
      "metadata": {
        "id": "1A8ofWjLFjm3"
      },
      "source": [
        "---\n",
        "### Joining\n",
        "Joins are useful when we want to combine two or more tables together, so we can do analysis on all of the tables. In `datascience`, we can use `join` and in `pandas` we can use `merge`. With both we need the information of the two tables and how we are joining on them (the appropriate columns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RMpSzgi0Fjm3",
      "metadata": {
        "id": "RMpSzgi0Fjm3"
      },
      "outputs": [],
      "source": [
        "# datascience\n",
        "table = Table().with_columns('first', make_array('i', 'c', 'c', 'a'), 'second', make_array('a', 'b', 'b', 'j'), 'third', make_array('c', 'd', 'e', 'f'))\n",
        "table2 = Table().with_columns( 'another', make_array('i', 'a', 'a', 'a'), 'fourth', make_array('a', 'b', 'b', 'j'), 'fifth', make_array('c', 'd', 'e', 'f'))\n",
        "print(table)\n",
        "print()\n",
        "print(table2)\n",
        "table.join('first', table2, 'fourth') # join table and table 2 together so columns first and fourth match values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3uRaT9_V1lb",
      "metadata": {
        "id": "e3uRaT9_V1lb"
      },
      "source": [
        "This took my brain a bit to understand, so here is an image that might be helpful. Also, read the text below to check that it matches your understanding of how the tables were joined above.\n",
        "\n",
        "![](TableJoinExample.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_piRSyBtFjm3",
      "metadata": {
        "id": "_piRSyBtFjm3"
      },
      "source": [
        "In the above code block, we create two different tables. When we call the `join()` function on these two tables, we take the cross product of the rows of both tables (every combination of rows that could happen between both tables) and then filter this out based on the columns we specify that need to be the same. In this case we have row `first` from the first table and row `fourth` from the second table, therefore we can only keep rows that have a value in `first` from the first table and `fourth` from the second table that are the same. In our example, the similar value is `first` and `fourth` is the value `a` (we see it in the last row of the `first` column and the first row of the `fourth` column). We then look at the values in these two rows and create a table with the values. Similarly, we can replicate this in `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0wFDkKEJFjm3",
      "metadata": {
        "id": "0wFDkKEJFjm3"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data = {'first': ['i', 'c', 'c', 'a'], 'second': ['a', 'b', 'b', 'j'], 'third': ['c', 'd', 'e', 'f']})\n",
        "df2 = pd.DataFrame(data = {'another': ['i', 'a', 'a', 'a'], 'fourth': ['a', 'b', 'b', 'j'], 'fifth': ['c', 'd', 'e', 'f']})\n",
        "print(df)\n",
        "print()\n",
        "print(df2)\n",
        "df.merge(df2, left_on = 'first', right_on = 'fourth', how = \"inner\") # merge df and df2 using an inner join using columns first and fourth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xp2beiRGFjm3",
      "metadata": {
        "id": "xp2beiRGFjm3"
      },
      "source": [
        "In the `pandas` code above, we have an extra argument that we need to specify: how. There are many types of joins that we can do with data. In `datascience`, the only option we can do is an inner join, but in `pandas`, we have the option to do inner, left, right, outer joins. For more information about these types of joins, check out this page: http://pandas.pydata.org/pandas-docs/version/0.19.1/generated/pandas.DataFrame.merge.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Fi550keWJ36",
      "metadata": {
        "id": "2Fi550keWJ36"
      },
      "source": [
        "Here is another example of join and a schematic that hopefully helps with this concept.\n",
        "![](TableJoinExample2.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-UhmTN96WfO4",
      "metadata": {
        "id": "-UhmTN96WfO4"
      },
      "outputs": [],
      "source": [
        "table = Table().with_columns('a', make_array(9, 3, 3, 1),\n",
        "    'b', make_array(1, 2, 2, 10),\n",
        "    'c', make_array(3, 4, 5, 6))\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rTy7NgZ4WjU_",
      "metadata": {
        "id": "rTy7NgZ4WjU_"
      },
      "outputs": [],
      "source": [
        "table2 = Table().with_columns( 'a', make_array(9, 1, 1, 1),\n",
        "'d', make_array(1, 2, 2, 10),\n",
        "'e', make_array(3, 4, 5, 6))\n",
        "table2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vYeF4ox_Wlw4",
      "metadata": {
        "id": "vYeF4ox_Wlw4"
      },
      "outputs": [],
      "source": [
        "table.join('a', table2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XfEjO1dvWnI4",
      "metadata": {
        "id": "XfEjO1dvWnI4"
      },
      "source": [
        "![](https://github.com/tmckim/materials-fa23-colab-working/blob/main/lab/lab08/TableJoinExample2.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sOJnW5zJFjm1",
      "metadata": {
        "id": "sOJnW5zJFjm1"
      },
      "source": [
        "---\n",
        "### Export to CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mhO4ao09Fjm1",
      "metadata": {
        "id": "mhO4ao09Fjm1"
      },
      "source": [
        "When we want to convert a Table to a csv file, we first need to convert it to a DataFrame and then to a csv file. In `pandas`, we can get rid of this intermediate step because we already have a DataFrame!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zldEAh_tFjm1",
      "metadata": {
        "collapsed": true,
        "id": "zldEAh_tFjm1"
      },
      "outputs": [],
      "source": [
        "dementia_table.to_df().to_csv('dementia_datascience.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZgJlvte4Fjm1",
      "metadata": {
        "collapsed": true,
        "id": "ZgJlvte4Fjm1"
      },
      "outputs": [],
      "source": [
        "dementia_df.to_csv('dementia_dataframe.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WllE04OmFjm3",
      "metadata": {
        "id": "WllE04OmFjm3"
      },
      "source": [
        "---\n",
        "### Reading `pandas` Documentation\n",
        "There are many more functions and methods you can call with `pandas` to do more cool things with Series and DataFrames. One way to learn more about this is by looking through the `pandas` documentation. The documentation has all the different functions associated with `pandas`, and descriptions about what they do, how you use them, and some examples.\n",
        "\n",
        "Some tips for reading through the documentation:\n",
        "* For various functions there are LOTS of different parameters that you can call, usually there are only a few that are important (usually related to the data you are working with and specifying how to run the functions). There are some parameters that are optional and you do not have to specify (automatically Pandas will use default settings for these functions). For example, for joins, an inner join is the default setting but if needed, you can say you want to do an outer join etc.\n",
        "* Another useful parameter is the `inplace` parameter. When set to true, the data is renamed/the function is run in place (a copy of the new data with the function applied is NOT created)\n",
        "* For quick lookup for a specific function: in the notebook you can put your cursor on a Pandas function and hover over it until the documentation appears. You can then open the documentation as new tab on the side of the browswer window."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2yrXaCLoGA7k",
      "metadata": {
        "id": "2yrXaCLoGA7k"
      },
      "source": [
        "## Lab Complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZV1br5HZGGPw",
      "metadata": {
        "id": "ZV1br5HZGGPw"
      },
      "outputs": [],
      "source": [
        "# Run this cell for fun\n",
        "from IPython.display import HTML\n",
        "HTML('<img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExdHFvM3pkNWR3azBhZTJ6OHVxcnRmYjYzM3Rqc2w0dWM0aHY1dHp6YSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/CjmvTCZf2U3p09Cn0h/giphy.gif\">')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yUFThzYcGJ68",
      "metadata": {
        "id": "yUFThzYcGJ68"
      },
      "source": [
        "### **Important submission steps:**\n",
        "1. Choose **Save** (and make sure you've already saved a copy in your drive) from the **File** menu.\n",
        "2. You will make sure your notebook file is saved in the following steps.\n",
        "3. You will submit the notebook for this assignment to the corresponding Assignment on the WebCampus (Canvas) course website.\n",
        "\n",
        "**It is your responsibility to make sure your work is saved before following the instructions in the last cell.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1BEgh7PFGQIM",
      "metadata": {
        "id": "1BEgh7PFGQIM"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
        "**Please save (or check again) before exporting!**\n",
        "You will save the notebook file (.ipynb):\n",
        "\n",
        "\n",
        "1.   Go to `\"File > Download\"` and choose the **.ipynb format** (first option)\n",
        "  - This will save a copy of the python notebook file- extension .ipynb- in the Downloads folder on your computer (or wherever you have opted to save files)\n",
        "\n",
        "\n",
        "2. If the above option is not available to you, make sure to use ctrl + s on a pc (press both keys at same time, do not include the + sign) or command + s (press both keys at same time, do not include the + sign) for apple devices. Look at the top of the Menu in google colab, and toward the middle, it might say that changes were saved.\n",
        "  * If you want to check that things were saved recently, go to your Google drive (via an online browser or from the app) and check the timestamp for when your notebook was last updated. If it wasn't saved recently, go back to the tab where you have your notebook open and resave.\n",
        "  * The notebook file `\"Copy of lab10.ipynb\"` will be in your google drive under the `\"Colab Notebooks\"` folder. (see info at top for more on where things get saved)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fYG3a3V8aM6M",
      "metadata": {
        "id": "fYG3a3V8aM6M"
      },
      "source": [
        "## Credits\n",
        "\n",
        "Data example and some code adapted from [Ruslan Klymentiev](https://pyforneuro.com/)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "otter": {
      "OK_FORMAT": true,
      "tests": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
